\input{pre.tex}
\newcommand{\eto}{\stackrel{=}{\to}}
\fontfamily{qcr}\selectfont 
%\usepackage[backend=bibtex]{biblatex}
\usepackage[
backend=biber,
style=alphabetic,%firstinits,
citestyle=ieee-alphabetic,
%natbib=true,
%uniquelist=false,
maxnames=10,
sorting=ynt
]{biblatex}
\addbibresource{writeup/article/refs.bib}
\usepackage{adjustbox}
%\title{\vspace{-1cm}}
\title{The Probabilistic Method}
\usepackage{quiver}
\author{Instructor: Noga Alon\\Notes by Nilava Metya}
\date{Spring 2024}
\makeatletter
\renewcommand{\@chapapp}{Lecture}
\makeatother

\begin{document}

\maketitle
\tableofcontents

\chapter{Examples\hfill\small$01/30/2024\qquad$}

\section{Philosophy}
Main philosophy of the probabilistic method: To prove existence of a structure (or a substructure of a given one), define a probability space of structures, and show that a random point in it satisfies the required properties with positive (often high) probability.

We will look at two examples today.

\section{Example: Ramsey Theory}

\begin{defn}[Ramsey numbers]
For $k,\l\geq 1$, let $r=r(k,\l)$ be the smallest integer, if there exists any, satisfying the following property: for every coloring of edges of $G=K_r$ (the complete graph on $r$ nodes) by \red~and \blue, either $\exists$ a  blue $K_k\subseteq G$ or a red $K_{\l}\subseteq G$.
\end{defn}
\begin{ex}
$r(3,3)=6$.
\end{ex}

A special case of Ramsey's theorem says that $\exists r(k,l)<\infty\forall k,l$. The proof, by induction (using Erd\"os-Szekeres theorem), gives $\ds r(k,\l)\leq\binom{k+\l-2}{k-1}$. In particular, $r(k,k) \leq \binom{2k-2}{k-1} <4^k$.

\begin{rmk}
The following are easy to observe: $r(k,\l)=r(l,k), r(1,\l)=1, r(2,\l)=\l$.
\end{rmk}

All the exactly known Ramsey numbers for $\l\geq k\geq 3$ are
$r(3,3)=6, r(3,4)=9, r(3,5)=14, r(3,6)=18, r(3,7)=23, r(3,8)=28, r(3,9)=36, r(4,4)=18, r(4,5)=25$. It is only known that $41\leq r(3,10)\leq 42, 36\leq r(4,6)\leq 40, 43\leq r(5,5)\leq 48$, and some similar bounds for other Ramsey numbers.

\begin{thm}[Erdos '47]
If $\ds\binom n k 2^{1-\binom k 2} < 1$ then $r(k,k)>n$. Therefore $r(k,k)\geq \left[1-o(1)\right]\frac{k}{e} 2^{\frac{k-1}2}$.
\end{thm}
\begin{pf}
Take the complete graph on $n$ labelled vertices $[n] = \set{1,\cdots,n}$. Color each edge $\set{i,j}$ (for $1\leq i<j\leq n$) randomly uniformly and independently either \red~or \blue. For fixed $K\subseteq[n]$ with $k=\abs K$, the probability that the graph induced by $K$ is monochromatic is $\ds{\color{red}2^{-\binom k 2}} + {\color{blue}2^{-\binom k 2}} = 2^{1-\binom k 2}$. So 
\begin{align*}
\ds\P{\exists \text{ such monochromatic }K} &\leq \sum_{\substack{K\subseteq [n]\\ \abs K = k}} \P{K \text{ induces a monochromatic graph}} \\
&= \binom n k 2^{1-\binom k 2} \stackrel{\text{given}}{<} 1.
\end{align*}
Therefore, $\ds\P{\not\exists \text{ such monochromatic }K} >0$. This means $r(k,k)>n$, which proves the first part.

Now, \begin{align*}
\binom n k 2^{1-\binom k 2} \leq 2 \left(\frac{en}{k}\right)^k\cdot 2^{-\binom k2} = 2\left(\frac{en}{2^{ \frac{k-1}{2}}\cdot k }\right)^k
\end{align*}
where the first inequality is due to $\ds\binom a b \leq \left(\frac{ea}{b}\right)^b$. If $\frac{en}{2^{ \frac{k-1}{2}}\cdot k }<1-\epsilon$ then for $k>k_0(\epsilon)$ for some $k_0(\epsilon)$, the RHS is $<1$. This implies that $r(k,k) \geq \left[1-o(1)\right]\frac{k}{e} 2^{\frac{k-1}2}$.\footnote{
Explanation for the last `implies': We note that for every $n$ satisfying the given condition, we have $r(k,k)>n$. Now for any $n<\left[1-\epsilon\right]\frac{k}{e} 2^{\frac{k-1}2}$, the condition is satisfied. Thus, $r(k,k)$ is more than all such $n$'s, which is written as $\left[1-o(1)\right]\frac{k}{e} 2^{\frac{k-1}2}$.
}
\qed\end{pf}

\rmk{
The lower bound was improved only by a factor of two since $1947$.\\
The upper bound was improved several times, last time in $2023$ by Campos, Griffiths, Morris, Sahasrabudhe to $(4-\epsilon)^k$, for an absolute constant $\epsilon>0$.\\
Open: Does $\lim r(k,k)^{1/k}$ exist (for USD 100)? If exists, find it (for USD 250).
}

\rmk{
Open problem: Find an explicit coloring showing $r(k,k)>1.0001^k$.
}

\rmk{This proof provides a randomized algorithm for finding a coloring that shows  $r(k,k) > \left\lfloor\sqrt{2^k}\right\rfloor$. But given such a coloring, we don't know how to efficiently check that $\not\exists$ a monochromatic $K_k$.
}

\section{Example: Dominating Sets}

\begin{defn}
If $G=(V,E)$ is a graph, we say $S\subseteq V$ is dominating if $\forall v\in V\smallsetminus S\exists u\in S$ such that $ \set{u,v}\in E$.
\end{defn}

\ex{
The set of bold vertices in \begin{tikzcd}
	\circ & \bullet & \circ \\
	\bullet & \circ
	\arrow[no head, from=1-1, to=1-2]
	\arrow[no head, from=1-2, to=1-3]
	\arrow[no head, from=1-2, to=2-2]
	\arrow[no head, from=1-1, to=2-1]
	\arrow[no head, from=2-1, to=2-2]
	\arrow[no head, from=1-1, to=2-2]
\end{tikzcd} form a dominating set.
}

\begin{thm}
If $G=(V,E)$ is a graph with $\abs V = n$ and minimum degree $\delta$, then it has a dominating set of size at most $\ds n\cdot \frac{1+\ln(1+\delta)}{1+\delta}$.
\end{thm}

\begin{pf}
Let $p=\frac{\ln(1+\delta)}{1+\delta}$. Clearly $p\in [0,1]$. Let $X\subseteq V$
 be a random subset of $V$ obtained by choosing each $v\in V$ to randomly and independently lie in $X$ with probability $p$. Since $X$ is not necessarily a dominating set, we can \textit{alter} it by $$Y_X\sett\set{v\in V\smallsetminus X\st \not\exists u\in X \text{ with } \set{u,v}\in E}.$$
By construction, $X\sqcup Y_X$ is a dominating set (note that they are disjoint).

Let's estimate the expected size of $X\cup Y_X$. First observe that $\E{\abs{X\cup Y_X}} = \E{\abs X + \abs {Y_X}}$ due to disjointness, and this is further equal to $\E{\abs X} + \E{\abs {Y_X}}$ by linearity of expectation.\\
$\abs X$ is a sum of independent indicators, one for each vertex which takes $1$ with probability $p$ and $0$ with probability $1-p$. So $\E{\abs X} = np$.\\
Note that $\P{v\in Y_X} = \P{v\notin X}\cdot \P{\text{no neighbor of } v \text{ is in } X} = (1-p)^{d_v} \leq (1-p)^{1+\delta} =\frac{1}{1+\delta}$ where $d_v$ is the degree of $v$ in $G$. Again $\abs{Y_X} = \sum_{v\in V} \pmb 1_{v\in Y_X}$ whence $\E{\abs {Y_X}} \leq \frac n {1+\delta}$. \\
This means $\E{\abs{X\cup Y_X}} \leq n\left[\frac{1+\ln(1+\delta)}{1+\delta}\right]$. Since the `average size' of a dominating set is less than or equal to the given quantity, $\exists$ a choice of $X$ such that $X\cup Y_X$ is a dominating set of size at most $\ds n\cdot \frac{1+\ln(1+\delta)}{1+\delta}$.
\qed\end{pf}

\rmk{We used \textit{linearity of expectation}: $\E{X+Y} = \E X + \E Y$. We also used \textit{alteration}: making a change after initial random choice, in this case we added $Y_X$ to $X$. (To be discussed more)}

\rmk{Here $\exists$ an efficient algorith to find such a dominating set. Start with $\varnothing$ and keep adding vertices that dominate maximum of yet non-dominated vertices.}

\rmk{Estimate is essentially that for $n\gg\delta\gg1$.}



\chapter{Examples\hfill\small$02/01/2024\qquad$}

Examples continued from last lecture.

\section{Example: Hypergraph $2-$coloring}

\begin{defn}
A \textit{hypergraph} is a pair $H=(V,E)$ of (finitely many) vertices $V$ and edges $E\subseteq 2^V$.

We say a hypergraph is \textit{$n-$uniform} if $\abs e=n\forall e\in E$. In particular, graphs are $2-$uniform hypergraphs.

We say a hypergraph is said to be \textit{$2-$colorable} if there exists a coloring of $V$ with \red~and \blue~with no monochromatic edge.
\end{defn}

We define the quantity $$m(n)\sett \min \set{\abs E \st (V,E) \text{ is } n- \text{uniform hypergraph and not } 2-\text{colorable}}$$ and interested in its asymptotics.

It is known that $m(1)=1, m(2)=3, m(3)=17, m(4)=23$ and for $n\geq 5$, $m(n)$ are unknown.

\begin{prop}
$m(n)\geq 2^{n-1}$ for $n\geq 2$.
\end{prop}

\pf{
For the sake of contradiction, let $H=(V,E)$ be $n-$uniform with $\abs E < 2^{n-1}$. We will show that $H$ is $2-$colorable. Color randomly each vertex independently either red or blue with probability half for each color. For each edge $e\in E$, let $A_e$ be the event that $e$ is monochromatic. Then $\P{A_e} = 2\cdot \left(\frac{1}{2}\right)^n = 2^{1-n}$. This means that $\P{\cup_{e\in E}A_e} \leq \sum_{e\in E}\P{A_e} = \abs E \cdot 2^{1-n}$ which is less than $1$ by assumption. This means that the event that no edge is monochromatic has positive probability, implying that there is a coloring for which there is no monochromatic edge. By definition, this is a $2-$coloring. 
\qed}

\rmk{The proof for lower bound of $r(k,k)$ is a special case. Take $n={k\choose 2}$. Vertices of the hypergraph are $E(K_n)$ and hyperedges are collections of $k\choose 2$ edges of $K_n$ that form a $k-$clique. So number of hyperedges is $n\choose k$.
}

\rmk{It can be shown that $m(n)\leq \cO(n^22^{n-1})$, that is $\exists c>0$ such that $m(n)\leq cn^22^{n-1}$ for all large $n$. Indeed if we take $2n^2$ vertices and $cn^22^{n-1}$ random subsets of size $n$, then with positive probability, every set of $n^2$ vertices contains an edge. So not $2-$colorable.\\
Note that the interesting quantity here is $\frac{m(n)}{2^{n-1}}$ which is the expected number of monochromatic edges in a random coloring. Thus $\ds1\leq \frac{m(n)}{2^{n-1}}\leq \cO(n^2)$.
}


Lower bound for $\frac{m(n)}{2^{n-1}}$ has been improved by Beck, by Radhakrishnan + Srinivasan. Best (short) proof is by Cherkashin and Kozik which is the following.

\begin{thm}
If $\exists k\geq 1, 0\leq p\leq 1$ such that $k(1-p)^n+k^2p<1$ then $m(n)>k\cdot 2^{n-1}$.
\end{thm}

\pf{
Let $n,k,p$ be as in the hypothesis of the theorem we're proving. Let $H=(V,E)$ be an $n-$uniform graph with $\abs E=k\cdot 2^{n-1}$. For each $v\in V$ pick $x_v\in [0,1]$ uniformly randomly. (We can assume that these $x_v$'s are unique because any two of them are equal with $0$ probability). These $x_v$'s define an ordering on the vertices, that is, we say $v<u$ iff $x_v<x_u$.

Now go over the vertices in increasing order and color each vertex \blue~ unless forced to color it \red~(namely, the vertex appears as the last vertex in an otherwise blue edge). By construction, there is no blue edge. But there can be a red edge. Let's look at probability that such a thing happens.

Define $L=\left[0,\frac{1-p}{2}\right), M=\left[\frac{1-p}2,\frac{1+p}2\right), R=\left[\frac{1+p}2,1\right]$. Let $A_e$ be the event that edge $e\in E$ is fully contained in $L$ or fully contained in $R$, and define $A\sett \bigcup_{e\in E}A_e$. Then $\P{A_e} = \P{x_v\in L\forall v\in e} + \P{x_v\in R\forall v\in e} = 2\P{x_v\in L\forall v\in e} = 2 \cdot\left(\frac{1-p}{2}\right)^n$. Thus \begin{align*}
\P A &\leq \sum_{e\in E} \P{A_e} \\
&\leq k\cdot 2^{n-1} \cdot 2 \cdot \left(\frac{1-p}{2}\right)^n \\
&= k(1-p)^n.
\end{align*}
Suppose the event $\ds\bigcup_{e\in E} A_e$ does not happen and there is a red edge. The former means every edge has one vertex each in at least two of $L,M,R$. Consider the first red edge $\color{red} e_0$, that is, the edge $\color{red} e$ with lowest value of $\ds\min_{v\in {\color{red}e}}x_v$ among red edges. Let $\color{red}v_0$ be the first vertex in $\color{red} e_0$. Clearly ${\color{red} v_0}\notin R$, else $\color{red} e_0$ would be completely in $R$. Also, ${\color{red} v_0}\notin L$ because otherwise $\color{red} v_0$ is the last edge of some otherwise blue edge which would hence completely be in $L$. Thus ${\color{red}v_0}\in M$. Say $\color{red} v_0$ is the last vertex of ${\color{blue} f_0}\in E$. Altogether, we care that there are two edges ${\color{red}e_0},{\color{blue}f_0}$ with $e_0\cap f_0 = \set{v_0}$ and $v_0\in M$, also called a \textit{conflicting} pair of edges. Also in this case, the probability that $v_0$ is the last vertex of ${\color{blue}f_0}$ is $\P{x_u \leq x_{v_0} \forall u\in f_0\smallsetminus\set{v_0}} = x_{v_0}^{n-1}$, and the probability that $v_0$ is the first vertex of ${\color{red}e_0}$ is $\P{x_u \geq x_{v_0} \forall u\in e_0\smallsetminus\set{v_0}} = (1-x_{v_0})^{n-1}$, because $\abs{e_0} = \abs{f_0} = n$ (by $n-$regularity of $H$). Thus 
\begin{align*}
\P{A^c\cap \set{\exists\text{ red edge}}} &\leq \P{\text{there is a conflicting pair of edges}}\\
&\leq \sum_{\substack{(e,f)\in E\times E\\ \abs {e\cap f}=1}} \P{(e,f)\text{ is a conflicting pair}} \\
&= \sum_{\substack{(e,f)\in E\times E\\ \abs {e\cap f}=1}} \P{\left(e\cap f \subseteq M\right)\cap \left(e\smallsetminus(e\cap f) \subseteq L\right) \cap \left(f\smallsetminus(e\cap f) \subseteq R\right)}\\
&= \sum_{\substack{(e,f)\in E\times E\\ \abs {e\cap f}=1}} \P{e\cap f \subseteq M} \cdot\P{e\smallsetminus(e\cap f) \subseteq L} \cdot\P{f\smallsetminus(e\cap f) \subseteq R}\\
&=\sum_{\substack{(e,f)\in E\times E\\ \abs {e\cap f}=1}} p \cdot x_{e\cap f}^{n-1}\cdot (1-x_{e\cap f})^{n-1} \\
&\leq \sum_{\substack{(e,f)\in E\times E\\ \abs {e\cap f}=1}} p \cdot \max_{x\in M}\left[x(1-x)\right]^{n-1} \\
&\leq (k\cdot 2^{n-1})^2 \cdot p \cdot \max_{x\in M}\left[x(1-x)\right]^{n-1}\\
&= k^2 \cdot 4^{n-1}\cdot p\cdot \frac{1}{4^{n-1}} = pk^2
\end{align*}
So $\P{\exists\text{ red edge}} \leq \P A + \P{A^c\cap \set{\exists\text{ red edge}}} \leq k(1-p)^n + kp^2$. This quantity is $<1$, whence $\P{\not\exists\text{ red edge}} >0$. This means that there is a coloring such that there is no red edge (there was no blue edge by construction). By definition, this is a $2-$coloring. So $m(n)$ must be greater than the number of edges of this graph, namely $k\cdot 2^{n-1}$.
\qed}

\begin{cor}
$m(n) > 2^{n-2}\cdot \sqrt{\frac{n}{\ln n}}$.
\end{cor}
\pf{
If $k=\frac{1}{2}\sqrt{\frac{n}{\ln n}}$ and $p = \frac{\ln n}{n}$. Then $1-p\leq e^{-p}\implies k(1-p)^n\leq ke^{-pn} = \frac{k}{n}$. Therefore $k^2p+k(1-p^n) \leq \frac{n}{4\ln n}\cdot\frac{\ln n}{n} + \frac{\sqrt{n}}{2n\sqrt{\ln n}} = \frac{1}{4} + \frac{1}{2\sqrt{n \ln n}} < 1$. By the above theorem, $m(n)>k\cdot 2^{n-1} = 2^{n-2}\cdot\sqrt{\frac{n}{\ln n}}$.\qed
}


\section{Example: Set Pairs}
\begin{thm}[Bollobas] Let $(A_i,B_i)$ for $1\leq i\leq h$ be pairs of subsets of $\Z$ satisfying that $\ds A_i\cap B_i=\varnothing\forall i, A_i\cap B_j\neq \varnothing \forall i\neq j$ and $\abs{A_i}=k,\abs{B_i}=\ell\forall i$. Then $h\leq {k+\ell\choose k}$. \\
(This is tight: Take $\abs{X}=k+\ell$ and $(A_i,B_i)$ are partitions of $X$ to disjoint sets of sizes $k,\ell$.)
\end{thm}

\begin{pf}
Order $\ds\bigcup_{i=1}^h A_i\cup B_i$ randomly. Let $E_i$ be the event that $A_i$ precedes $B_i$, that is, $\max A_i < \min B_i$. Note that $\P{E_i} = {k+\ell\choose k}^{-1}$. Also, events are pairwise disjoint, since if both $E_i,E_j$ occur together and (WLOG) $\max A_i \geq \max A_i$ then $\min B_i > \max A_i \geq \max A_j$ so $A_j\cap B_i=\varnothing$ which cannot happen. This means that $h\cdot {k+\ell\choose k}^{-1}=\sum_i\P{E_i} = \P{\bigcup_i E_i} \leq 1.$
\qed\end{pf}



\chapter{$\mathbb E\Sigma = \Sigma\mathbb E$ or $\mathbb E\int = \int \mathbb E$\hfill \small $02/06/2024\qquad$}

\begin{thm}[Linearity of Expectation(LoE)]\label{LOE}
If $X_1,\cdots,X_n$ are random variables and $X =\sum c_iX_i$ for some $c_i\in\R$, then $\E X=\sum c_i\E {X_i}$.
\end{thm}
\pf{Follows from definition of expectation.\qed}

The applications often try to define $X_i$ so that computing $\E{X_i}$ is simple: often $X_i$ are indicators. Usually one uses the fact that $\exists$ a point with $X>\E X$ (or $X<\E X$), unless each point takes equal value.

\section{Example: Sum-free subsets}

\begin{defn}
$B\subseteq\text{some Abelian group}$ is said to be sumfree if $(B+B)\cap B=\varnothing$, that is, $\not\exists a,b,c\in B$ such that $a+b=c$.
\end{defn}

\begin{thm}
$\forall A\subseteq \Z\smallsetminus \set0$ with $\abs A=n, \exists B\subseteq A$ such that $B$ is sumfree and has at least $\frac{n}{3}$ elements.
\end{thm}
\begin{pf}
Let $p=3k+2$ be a prime such that $\prod_{a\in A} a$ is not divisible by $p$. Take $M = \set{k+1,\cdots,2k+1}$. Note that $M$ is sumfree modulo $p$. Pick $x\in \set{1,\cdots,p-1}$ uniformly randomly. Put $B_x=\set{a\in A\st (ax)\%p \in M}$. This implies that $\forall x, B_x$ is sumfree in $\Z$. Indeed if $(ax)\%p+(bx)\%p = (cx)\%p$ for some $a,b,c\in M$ then $(a+b)x\cong cx\pmod p$ whence $a+b\cong c\pmod p$ because $(x,p)=1$, contradicting the fact that $M$ is sumfree modulo $p$. We compute $\E{\abs{B_x}}$. $B_x$ comprises all those elements $a\in A$ such that $ax$ is some element in $M$ modulo $p$. So for each $a$ take an indicator $\pmb 1_{a\in B_x} = \pmb 1_{(ax)\%p\in M\st x}$. With this, $\ds\abs{B_x} = \sum_{a\in A} \pmb 1_{(ax)\%p\in M\st x}$ and $\P{(ax)\%p\in M\st x} = \frac{k+1}{p-1}>\frac{1}{3}$. Thus $\ds\E{\abs{B_x}} = \sum_{a\in A}\E{\pmb 1_{(ax)\%p\in M\st x}} = \sum_{a\in A}\P{(ax)\%p\in M\st x} > \abs A/3 = \frac{n}{3}$. So $\exists x$ for which $\abs{B_x} > \frac{1}{3}$.
\qed\end{pf}

\rmk{Eberhardt, Green+Manners showed that $\frac{1}{3}$ is tight. however it is conjectured that $\forall c>0\exists n_0=n_0(c)$ such that if $n>n_0$ then $\forall A\subseteq \Z\smallsetminus\set{0}$ and $\abs A=n$, $A$ contains a sumfree subset of size at least $\frac{n}{3}+c$.}

\rmk{Proof gives an efficient deterministic algorithm to find such $B$, given $A$.}

\rmk{Alon+Kleitman proved that $\forall$ Abelian group $H$ and $\forall A\subseteq H\smallsetminus\set{0}$ with $\abs A=n, \exists B\subseteq A$ such that $B$ is sumfree and has size $>\frac{2n}{7}$, where $\frac{2}{7}$ is tight as shown by $A=\left(\Z_7\right)^k\smallsetminus\set 0$.}

\section{Hamilton paths}
Historically the first application of the probabilistic method in combinatorics is considered to be a result of Szele ($1943$) on Hamilton paths in tournaments.

\begin{defn}[Tournament, Hamilton path, Hamilton cycle]
A \textit{tournament} $T$ on $n$ vertices is an oriented complete graph on $n$ vertices.\\
A \textit{Hamilton path} in $T$ is a directed path passing through every vertex exactly once.\\
A \textit{Hamilton cycle} in $T$ is a directed cycle passing through every vertex exactly once.
\end{defn}

$T$ is said to be \textit{transitive} if it contains no directed cycles (equivalently, $\exists \sigma\in S_n$ such that $(\sigma_i,\sigma_j)\in E\iff i<j$).\\
Can prove by induction: Every tournament contains a Hamilton path.\\
So, a transitive tournament has only one such path.

Denote $P(n) =$ max possible number of Hamilton paths in a tournament on $n$ vertices.

\begin{thm}[Szele] $P(n)\geq \frac{n!}{2^{n-1}}$.
\end{thm}
\begin{pf}
Let $T$ be a random tournament on $n$ vertices $\set{1,\cdots, n}$, that is, for each pair $\set{i,j}$ pick randomly uniformly either $(i,j)$ or $(j,i)$ to be and edge in $T$. We count the number of Hamilton paths $i_1\to \cdots \to i_n$. So, for each permutation $\sigma\in S_n$ consider the indicator $X_{\sigma} = \pmb 1_{\sigma_1\to\cdots\to \sigma_n \text{ is Hamilton path in }T}$. Then number of Hamilton paths in $T$ is $X_T=\sum_{\sigma\in S_n}X_{\sigma}$. Then $\E{X_T} = \sum_{\sigma\in S_n} \E{X_\sigma} \stackrel{(*)}{=} n!\cdot\P{1\to \cdots \to n\text{ is Hamilton path in }T} = \frac{n!}{2^{n-1}}$, where $(*)$ holds because $\P{1\to \cdots \to n\text{ is Hamilton path in }T} = \P{\sigma_1\to \cdots \to \sigma_n\text{ is Hamilton path in }T}$ for any $\sigma\in S_n$. Thus there is some tournament on $[n]$ which has at least $\frac{n!}{2^{n-1}}$ Hamilton paths, which simply implies that $P(n)\geq \frac{n!}{2^{n-1}}$.
\qed\end{pf}

Szele also proved (without using probability) that $P(n)\leq \cO\left(\frac{n!}{2^{3n/4}}\right)$ and that $\lim_{n\to\infty}\left(\frac{P(n)}{n!}\right)^{\frac{1}{n}}$ exists (thus between $\frac12$ and $2^{-\frac{3}{4}}$). It's conjectured to be $\frac{1}{2}$. \\
We'll see a proof of the above (proven) fact using some results on permanents of $0/1$ matrices and linearity of expectation.

\begin{defn}[Permanent]
The permanent of an $n\times n$ matrix $A=(a_{ij})$ is $\ds\per A = \sum_{\sigma\in S_n}\prod_{i=1}^n a_{i,\sigma(i)}$.
\end{defn}

If $T=(V,E)$ is a tournament on $V=[n]$, we can define its adjacency matrix $A=(a_{ij})$ where $a_{ij} = \pmb 1_{(i,j)\in E}$. Note that $\per A$ is equal to the number of spanning $1-$regular subgraphs of $T$, which is also equal to the number of subgraphs which are vertex disjoint unions of directed cycles. This quantity is at least as many as the number of Hamilton cycles in $T$. We will (prove and) use the following theorem:

\begin{thm}[Minc conjecture, proved by Bregman]\label{perm}
If $A=(a_{ij})\in\set{0,1}^{n\times n}$ then $$\ds\per A \leq \prod_{i=1}^n \left(r_i!\right)^{\frac{1}{r_i}}$$ where $\ds r_i = \sum_{1\leq j\leq n}a_{ij}$ is the number of $1$'s in row $i$.
\end{thm}
\rmk{This bound is tight for matrices with square blocks of $1's$. If $A$ is a square block containing only $1$'s, then $r_i=n$ whence the RHS of the above inequality is $n!$ which is precisely $\per A$, in this case. If $A = \begin{bmatrix}A_1\\&A_2\\&&\ddots\\&&&A_r\end{bmatrix}$ where $A_i\in \set{1}^{s_i\times s_i}$ then $\per A = \prod_{i=1}^r s_i!$ and the RHS is exactly this quantity.}


\chapter{Continued: $\mathbb E\int = \int\mathbb E$\hfill \small $02/08/2024\qquad$}

Last time we saw linearity of expectation and its application in Hamiltonian paths. 

We had stated \Cref{perm}: If $A=(a_{ij})\in \set{0,1}^{n\times n}$ and $r_i = \sum_j a_{ij}$ then $\per A\leq (\prod_i r_i!)^{\frac{1}{r_i}}.$ 

Assuming this theorem, we can upper bound $P(n) = $ maximum number of Hamiltonian paths in a tournament on $[n]$. Let's also define $H(n) = $ maximum number of Hamiltonian cycles in a tournament on $[n]$.

\begin{lemma}
$P(n)\leq H(n+1)\forall n$.
\end{lemma}

\begin{pf}
Let $T$ be a tournament on $[n]$ with $P(n)$ Hamilton paths. Let $T'$ be $T$ with an additional vertex with all edges between $x$ and $V(T)$ oriented randomly. For each fixed Hamilton path $P$ in $T$, let $X_P$ be the indicator that $P$ is a part of a Hamilton cycle in $T'$. But $\E{X_P} = \frac{1}{4}$ because among the following situations, only the blue situation is possible (so one out of four).

\begin{adjustbox}{width=\textwidth}
\begin{tikzcd}
	&& \bullet &&&&& \bullet &&&&& \bullet &&&&& \bullet \\
	\vdots &&& {\bullet_x} && \vdots &&& {\bullet_x} && \vdots &&& {\bullet_x} && \vdots &&& {\bullet_x} \\
	&& \bullet &&&&& \bullet &&&&& \bullet &&&&& \bullet
	\arrow[color={rgb,255:red,92;green,92;blue,214}, curve={height=18pt}, squiggly, from=1-3, to=2-1]
	\arrow[color={rgb,255:red,92;green,92;blue,214}, curve={height=18pt}, squiggly, from=2-1, to=3-3]
	\arrow[color={rgb,255:red,92;green,92;blue,214}, from=2-4, to=1-3]
	\arrow[color={rgb,255:red,92;green,92;blue,214}, from=3-3, to=2-4]
	\arrow[from=2-9, to=1-8]
	\arrow[from=2-9, to=3-8]
	\arrow[curve={height=18pt}, squiggly, from=1-8, to=2-6]
	\arrow[curve={height=18pt}, squiggly, from=2-6, to=3-8]
	\arrow[curve={height=18pt}, squiggly, from=1-13, to=2-11]
	\arrow[curve={height=18pt}, squiggly, from=2-11, to=3-13]
	\arrow[from=1-13, to=2-14]
	\arrow[from=3-13, to=2-14]
	\arrow[curve={height=18pt}, squiggly, from=1-18, to=2-16]
	\arrow[curve={height=18pt}, squiggly, from=2-16, to=3-18]
	\arrow[from=1-18, to=2-19]
	\arrow[from=2-19, to=3-18]
\end{tikzcd}
\end{adjustbox}
By linearity of expectation, expected number of Hamiltonian cycles in $T'$ is $\frac{P(n)}{4}$ and this quantity is bounded above by $H(n+1)$.
\qed\end{pf}

\end{document}
